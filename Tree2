
package extractor;

import com.github.javaparser.*;
import com.github.javaparser.ast.*;
import com.github.javaparser.ast.body.*;
import com.google.gson.*;

import java.io.*;
import java.nio.file.*;
import java.util.*;

public class Extractor {

    public static void main(String[] args) throws Exception {

        if (args.length != 2) {
            System.out.println("Usage: Extractor <repo-path> <out-json>");
            return;
        }

        String repoPath = args[0];
        String outJson = args[1];

        File repoDir = new File(repoPath);
        if (!repoDir.exists()) {
            System.err.println("ERROR: Repository folder NOT found: " + repoDir.getAbsolutePath());
            return;
        }

        System.out.println("Scanning repo: " + repoDir.getAbsolutePath());

        // Configure parser properly
        ParserConfiguration config = new ParserConfiguration()
                .setLanguageLevel(ParserConfiguration.LanguageLevel.JAVA_11)
                .setAttributeComments(false)
                .setTabSize(4);

        JavaParser parser = new JavaParser(config);

        List<Map<String, Object>> fileResults = new ArrayList<>();

        Files.walk(Paths.get(repoPath))
                .filter(f -> f.toString().endsWith(".java"))
                .forEach(path -> {
                    try {
                        Map<String, Object> fileJson = processJavaFile(path.toFile(), parser);
                        fileResults.add(fileJson);

                    } catch (Exception ex) {
                        System.err.println("FAILED to process file: " + path);
                        ex.printStackTrace();
                    }
                });

        Map<String, Object> root = new HashMap<>();
        root.put("files", fileResults);

        Gson gson = new GsonBuilder().setPrettyPrinting().create();
        String jsonOutput = gson.toJson(root);

        Files.write(Paths.get(outJson), jsonOutput.getBytes());
        System.out.println("Wrote AST JSON → " + outJson);
    }

    private static Map<String, Object> processJavaFile(File file, JavaParser parser) throws Exception {
        Map<String, Object> fileJson = new HashMap<>();
        fileJson.put("path", file.getName());

        String code = new String(Files.readAllBytes(file.toPath()));

        ParseResult<CompilationUnit> result = parser.parse(code);

        if (!result.isSuccessful() || !result.getResult().isPresent()) {
            System.err.println("\n### PARSE FAILED for file: " + file.getName());
            for (Problem p : result.getProblems()) {
                System.err.println("Parser problem → " + p.toString());
            }
            fileJson.put("types", new ArrayList<>());
            return fileJson;
        }

        CompilationUnit cu = result.getResult().get();
        List<Map<String, Object>> typesList = new ArrayList<>();

        cu.findAll(ClassOrInterfaceDeclaration.class).forEach(c -> {
            Map<String, Object> typeJson = new HashMap<>();
            typeJson.put("name", c.getNameAsString());

            // FIELDS
            List<Map<String, Object>> fields = new ArrayList<>();
            c.getFields().forEach(f -> {
                Map<String, Object> fJson = new HashMap<>();
                fJson.put("name", f.getVariables().get(0).getNameAsString());
                fJson.put("type", f.getVariables().get(0).getTypeAsString());
                fields.add(fJson);
            });
            typeJson.put("fields", fields);

            // METHODS
            List<Map<String, Object>> methods = new ArrayList<>();
            c.getMethods().forEach(m -> {
                Map<String, Object> mJson = new HashMap<>();
                mJson.put("name", m.getNameAsString());
                mJson.put("returnType", m.getType().toString());
                mJson.put("parameters", m.getParameters().toString());
                methods.add(mJson);
            });
            typeJson.put("methods", methods);

            typesList.add(typeJson);
        });

        fileJson.put("types", typesList);
        return fileJson;
    }
}

=====


<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">

  <modelVersion>4.0.0</modelVersion>

  <groupId>com.example</groupId>
  <artifactId>javaparser-extractor</artifactId>
  <version>1.0-SNAPSHOT</version>

  <properties>
    <maven.compiler.source>11</maven.compiler.source>
    <maven.compiler.target>11</maven.compiler.target>
  </properties>

  <dependencies>
    <dependency>
      <groupId>com.github.javaparser</groupId>
      <artifactId>javaparser-core</artifactId>
      <version>3.25.4</version>
    </dependency>

    <dependency>
      <groupId>com.google.code.gson</groupId>
      <artifactId>gson</artifactId>
      <version>2.10.1</version>
    </dependency>
  </dependencies>

  <build>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-assembly-plugin</artifactId>
        <version>3.4.2</version>

        <configuration>
          <descriptorRefs>
            <descriptorRef>jar-with-dependencies</descriptorRef>
          </descriptorRefs>
          <archive>
            <manifest>
              <mainClass>extractor.Extractor</mainClass>
            </manifest>
          </archive>
        </configuration>

        <executions>
          <execution>
            <id>make-assembly</id>
            <phase>package</phase>          <!-- THIS TAG MUST BE <phase> -->
            <goals>
              <goal>single</goal>
            </goals>
          </execution>
        </executions>

      </plugin>
    </plugins>
  </build>

</project>



set AZURE_OPENAI_KEY=YOUR_KEY
set AZURE_OPENAI_ENDPOINT=https://<your-resource>.openai.azure.com/
set AZURE_DEPLOYMENT_CHAT=<your-chat-deployment>
set AZURE_DEPLOYMENT_EMBED=<your-embed-deployment>
set LEGACY_JAVA_REPO=C:\path\to\your\legacy_java_repo

Project Structure (0)

code_conversion_workspace/
  app.py                 # Streamlit app entry-point
  requirements.txt

  backend/
    __init__.py
    config.py
    llm_client.py
    ast_extractor.py
    chunker.py
    doc_generator.py
    validator.py
    converter.py
    test_generator.py
    data/
      (empty to start)

  java_parser_helper/
    pom.xml
    src/main/java/extractor/Extractor.java


You’ll also have your legacy Java repo somewhere else, e.g. C:\legacy_java_repo\... containing your big class and other files.
================================================================
1 requirements.txt

streamlit
openai
numpy
pydantic
requests
====================================================================
2. JavaParser helper (multi-class, nested classes, big files)
java_parser_helper/pom.xml

<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <groupId>com.example</groupId>
  <artifactId>javaparser-extractor</artifactId>
  <version>1.0-SNAPSHOT</version>

  <properties>
    <maven.compiler.source>11</maven.compiler.source>
    <maven.compiler.target>11</maven.compiler.target>
  </properties>

  <dependencies>
    <dependency>
      <groupId>com.github.javaparser</groupId>
      <artifactId>javaparser-core</artifactId>
      <version>3.25.4</version>
    </dependency>
    <dependency>
      <groupId>com.google.code.gson</groupId>
      <artifactId>gson</artifactId>
      <version>2.10.1</version>
    </dependency>
  </dependencies>

  <build>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-assembly-plugin</artifactId>
        <version>3.4.2</version>
        <configuration>
          <descriptorRefs>
            <descriptorRef>jar-with-dependencies</descriptorRef>
          </descriptorRefs>
          <archive>
            <manifest>
              <mainClass>extractor.Extractor</mainClass>
            </manifest>
          </archive>
        </configuration>
        <executions>
          <execution>
            <id>make-assembly</id>
            <phase>package</time>
            <goals>
              <goal>single</goal>
            </goals>
          </execution>
        </executions>
      </plugin>
    </plugins>
  </build>
</project>


java_parser_helper/src/main/java/extractor/Extractor.java

package extractor;

import com.github.javaparser.*;
import com.github.javaparser.ast.CompilationUnit;
import com.github.javaparser.ast.body.*;
import com.google.gson.GsonBuilder;

import java.io.Writer;
import java.nio.file.*;
import java.util.*;

public class Extractor {

    public static void main(String[] args) throws Exception {
        if (args.length < 2) {
            System.err.println("Usage: Extractor <repo-root> <out-json>");
            System.exit(1);
        }
        Path repo = Paths.get(args[0]);
        Path out = Paths.get(args[1]);

        JavaParser parser = new JavaParser();

        List<Map<String, Object>> files = new ArrayList<>();

        Files.walk(repo)
                .filter(p -> p.toString().endsWith(".java"))
                .forEach(p -> {
                    try {
                        String src = Files.readString(p);
                        ParseResult<CompilationUnit> result = parser.parse(src);
                        if (!result.isSuccessful() || !result.getResult().isPresent()) {
                            System.err.println("Parse failed for " + p);
                            return;
                        }
                        CompilationUnit cu = result.getResult().get();

                        Map<String, Object> fileObj = new LinkedHashMap<>();
                        fileObj.put("path", repo.relativize(p).toString());
                        fileObj.put("source", src);

                        List<Map<String, Object>> types = new ArrayList<>();
                        for (TypeDeclaration<?> td : cu.getTypes()) {
                            types.add(extractType(td));
                        }
                        fileObj.put("types", types);
                        files.add(fileObj);
                    } catch (Exception e) {
                        System.err.println("Failed parse " + p + ": " + e.getMessage());
                    }
                });

        Map<String, Object> root = new LinkedHashMap<>();
        root.put("files", files);

        try (Writer w = Files.newBufferedWriter(out)) {
            w.write(new GsonBuilder().setPrettyPrinting().create().toJson(root));
        }
        System.out.println("Wrote AST JSON to " + out.toAbsolutePath());
    }

    private static Map<String, Object> extractType(TypeDeclaration<?> td) {
        Map<String, Object> typeObj = new LinkedHashMap<>();
        typeObj.put("name", td.getNameAsString());
        typeObj.put("kind", td.getClass().getSimpleName());
        typeObj.put("modifiers", td.getModifiers().toString());

        List<Map<String, Object>> fields = new ArrayList<>();
        for (FieldDeclaration fd : td.getFields()) {
            for (VariableDeclarator var : fd.getVariables()) {
                Map<String, Object> f = new LinkedHashMap<>();
                f.put("name", var.getNameAsString());
                f.put("type", var.getType().asString());
                f.put("modifiers", fd.getModifiers().toString());
                fields.add(f);
            }
        }
        typeObj.put("fields", fields);

        List<Map<String, Object>> methods = new ArrayList<>();
        for (MethodDeclaration md : td.getMethods()) {
            Map<String, Object> m = new LinkedHashMap<>();
            m.put("name", md.getNameAsString());
            m.put("returnType", md.getType().asString());
            m.put("modifiers", md.getModifiers().toString());
            m.put("beginLine", md.getBegin().isPresent() ? md.getBegin().get().line : -1);
            m.put("endLine", md.getEnd().isPresent() ? md.getEnd().get().line : -1);
            m.put("body", md.getBody().isPresent() ? md.getBody().get().toString() : "");
            List<Map<String, String>> params = new ArrayList<>();
            md.getParameters().forEach(p -> {
                Map<String, String> param = new LinkedHashMap<>();
                param.put("name", p.getNameAsString());
                param.put("type", p.getType().asString());
                params.add(param);
            });
            m.put("parameters", params);
            methods.add(m);
        }
        typeObj.put("methods", methods);

        List<Map<String, Object>> inner = new ArrayList<>();
        for (BodyDeclaration<?> bd : td.getMembers()) {
            if (bd.isClassOrInterfaceDeclaration()) {
                inner.add(extractType((TypeDeclaration<?>) bd));
            }
        }
        typeObj.put("innerClasses", inner);

        return typeObj;
    }
}


Build once :

cd java_parser_helper
mvn -q clean package
cd ..

=====================================================================

3. Backend Python modules
backend/__init__.py

# empty file, just to make backend a package

=====================
backend/config.py

from __future__ import annotations
import os
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent

AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY", "")
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT", "")
AZURE_DEPLOYMENT_CHAT = os.getenv("AZURE_DEPLOYMENT_CHAT", "gpt-35-turbo")
AZURE_DEPLOYMENT_EMBED = os.getenv("AZURE_DEPLOYMENT_EMBED", "text-embedding-3-small")

DATA_DIR = BASE_DIR / "backend" / "data"
DATA_DIR.mkdir(parents=True, exist_ok=True)

AST_JSON_PATH = DATA_DIR / "ast.json"
PREPROCESSED_JSON = DATA_DIR / "pre_processed_files.json"

MAX_METHOD_CHARS = 6000
DOC_AUTO_RETRY = 1
DOC_VALIDATION_THRESHOLD = 0.9

JAVA_HELPER_DIR = BASE_DIR / "java_parser_helper"
JAVA_AST_OUT = AST_JSON_PATH

LEGACY_REPO_ENV = "LEGACY_JAVA_REPO"

================

backend/llm_client.py


from __future__ import annotations
import json
from typing import Any, Dict, List
from openai import OpenAI
from .config import (
    AZURE_OPENAI_KEY,
    AZURE_OPENAI_ENDPOINT,
    AZURE_DEPLOYMENT_CHAT,
    AZURE_DEPLOYMENT_EMBED,
)

client = OpenAI(api_key=AZURE_OPENAI_KEY, base_url=AZURE_OPENAI_ENDPOINT)


def embed_texts(texts: List[str]) -> List[List[float]]:
    if not texts:
        return []
    resp = client.embeddings.create(
        model=AZURE_DEPLOYMENT_EMBED,
        input=texts,
    )
    return [e.embedding for e in resp.data]


def chat_json(system_prompt: str, user_payload: Any, max_tokens: int = 1500) -> Dict[str, Any]:
    resp = client.chat.completions.create(
        deployment_id=AZURE_DEPLOYMENT_CHAT,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": json.dumps(user_payload)},
        ],
        max_tokens=max_tokens,
        temperature=0.0,
    )
    text = resp.choices[0].message.content
    try:
        return json.loads(text)
    except Exception:
        # try to salvage JSON substring if model adds text
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1:
            return json.loads(text[start : end + 1])
        raise

================
backend/ast_extractor.py

from __future__ import annotations
import json
import subprocess
import shutil
from pathlib import Path
from typing import Dict, Any

from .config import JAVA_HELPER_DIR, JAVA_AST_OUT, AST_JSON_PATH


def run_java_extractor(repo_path: str) -> None:
    jar_candidates = list((JAVA_HELPER_DIR / "target").glob("*jar-with-dependencies.jar"))
    if not jar_candidates:
        raise RuntimeError(
            "Java helper jar not found. Build it with `mvn -q clean package` in java_parser_helper/."
        )
    jar = jar_candidates[0]
    java = shutil.which("java")
    if not java:
        raise RuntimeError("`java` not found in PATH")

    cmd = [java, "-jar", str(jar), repo_path, str(JAVA_AST_OUT)]
    proc = subprocess.run(cmd, capture_output=True, text=True)
    if proc.returncode != 0:
        raise RuntimeError(f"Extractor failed: {proc.stderr}")
    print(proc.stdout)


def load_ast() -> Dict[str, Any]:
    if not AST_JSON_PATH.exists():
        return {"files": []}
    return json.loads(AST_JSON_PATH.read_text(encoding="utf-8"))

==================
backend/chunker.py (classes & inner classes, plus method splitting for large bodies)

from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List
from .config import MAX_METHOD_CHARS
from .llm_client import chat_json

@dataclass
class MethodSummary:
    class_name: str
    method_name: str
    signature: Dict[str, Any]
    description: str

SEGMENT_SYSTEM_PROMPT = """
You summarise one segment of a Java method.
Input JSON: {"methodName":"...", "segment":"<code>"}
Return JSON: {"summary":"short precise description of what this segment does"}
"""

METHOD_SYSTEM_PROMPT = """
You summarise a full Java method from multiple segment summaries.
Input:
{
  "method": {"name":"...", "returnType":"...", "parameters":[{"name":"...","type":"..."}]},
  "segments": ["...", "..."]
}
Return JSON: {"description":"short precise description of the method's purpose and behaviour"}
"""

def split_method_body(body: str) -> List[str]:
    if len(body) <= MAX_METHOD_CHARS:
        return [body]
    segments: List[str] = []
    current: List[str] = []
    size = 0
    for line in body.splitlines():
        current.append(line)
        size += len(line)
        if (
            size >= MAX_METHOD_CHARS
            or line.strip().endswith(";")
            or line.strip().startswith(("if", "for", "while", "switch"))
        ):
            segments.append("\n".join(current))
            current = []
            size = 0
    if current:
        segments.append("\n".join(current))
    return segments


def summarise_method(class_name: str, method_meta: Dict[str, Any]) -> MethodSummary:
    body = method_meta.get("body", "") or ""
    segments = split_method_body(body)
    seg_summaries: List[str] = []
    for seg in segments:
        payload = {"methodName": method_meta["name"], "segment": seg}
        j = chat_json(SEGMENT_SYSTEM_PROMPT, payload, max_tokens=300)
        seg_summaries.append(j.get("summary", ""))

    payload2 = {
        "method": {
            "name": method_meta["name"],
            "returnType": method_meta.get("returnType"),
            "parameters": method_meta.get("parameters", []),
        },
        "segments": seg_summaries,
    }
    j2 = chat_json(METHOD_SYSTEM_PROMPT, payload2, max_tokens=300)
    return MethodSummary(
        class_name=class_name,
        method_name=method_meta["name"],
        signature=payload2["method"],
        description=j2.get("description", ""),
    )


def flatten_types(ast_json: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    Flatten top-level and inner classes into a list of
    {"file":..., "qualified_name":..., "type_obj":...}
    """
    result: List[Dict[str, Any]] = []

    def walk_type(t: Dict[str, Any], file_path: str, prefix: str | None = None):
        qualified = t["name"] if not prefix else f"{prefix}.{t['name']}"
        result.append({"file": file_path, "qualified_name": qualified, "type_obj": t})
        for inner in t.get("innerClasses", []):
            walk_type(inner, file_path, qualified)

    for f in ast_json.get("files", []):
        p = f["path"]
        for t in f.get("types", []):
            walk_type(t, p, None)

    return result

=================
backend/validator.py (AST skeleton + LLM description validation)

from __future__ import annotations
from typing import Dict, Any, Set
from .llm_client import chat_json

DESCRIPTION_VALIDATOR_SYSTEM = """
You validate Java class documentation.

Input JSON:
{
  "skeleton": {...},    // AST-based class skeleton (name, fields, methods, innerClasses)
  "doc": {...}          // generated documentation components
}

Return JSON:
{
  "accuracy_percentage": 95.0,
  "completeness_percentage": 90.0,
  "explanation": "short explanation of gaps or misalignments"
}
Accuracy: how well descriptions match the intent implied by names and structure.
Completeness: how much of the skeleton is covered (fields, methods, inner classes).
Be conservative; do not give 100 unless you are confident it is exact.
"""

def skeleton_metrics(type_obj: Dict[str, Any], doc: Dict[str, Any]) -> Dict[str, Any]:
    ast_fields: Set[str] = {f["name"] for f in type_obj.get("fields", [])}
    ast_methods: Set[str] = {m["name"] for m in type_obj.get("methods", [])}

    doc_fields: Set[str] = set()
    doc_methods: Set[str] = set()
    for comp in doc.get("components", []):
        for f in comp.get("fields", []):
            doc_fields.add(f.get("name", ""))
        for m in comp.get("methods", []):
            doc_methods.add(m.get("name", ""))

    total_fields = len(ast_fields) or 1
    total_methods = len(ast_methods) or 1

    fields_cov = len(ast_fields & doc_fields) / total_fields
    methods_cov = len(ast_methods & doc_methods) / total_methods

    total = (fields_cov + methods_cov) / 2.0

    return {
        "total_fields": len(ast_fields),
        "fields_completeness_score": fields_cov * 100,
        "total_methods": len(ast_methods),
        "methods_completeness_score": methods_cov * 100,
        "total_completeness_percentage": total * 100,
    }


def validate_doc_against_ast(type_obj: Dict[str, Any], doc: Dict[str, Any]) -> Dict[str, Any]:
    skeleton = skeleton_metrics(type_obj, doc)
    payload = {"skeleton": type_obj, "doc": doc}
    desc = chat_json(DESCRIPTION_VALIDATOR_SYSTEM, payload, max_tokens=800)

    description = {
        "accuracy_percentage": desc.get("accuracy_percentage", 0.0),
        "completeness_percentage": desc.get("completeness_percentage", 0.0),
        "explanation": desc.get("explanation", ""),
    }
    return {
        "skeleton_validation": skeleton,
        "description_validation": description,
    }

================
backend/doc_generator.py (per-class doc generation + validation + retry)

from __future__ import annotations
import json
from typing import Any, Dict
from .chunker import summarise_method
from .validator import validate_doc_against_ast
from .config import DOC_AUTO_RETRY, DOC_VALIDATION_THRESHOLD
from .llm_client import chat_json

DOC_SYSTEM_PROMPT = """
You generate documentation for a single Java class.

Input JSON:
{
  "skeleton": {
    "className": "...",
    "kind": "...",
    "modifiers": "...",
    "fields": [{"name":"...","type":"...","modifiers":"..."}],
    "methods": [
        {"name":"...","returnType":"...","modifiers":"...","parameters":[{"name":"...","type":"..."}]}
    ],
    "innerClasses": [ { ... nested skeletons ... } ]
  },
  "methods": [
    {
      "name":"...",
      "summary":"short description of method behaviour",
      "parameters":[{"name":"...","type":"..."}],
      "returnType":"..."
    }
  ]
}

Output JSON format (strict):
{
  "components":[
    {
      "name":"<className>",
      "description":"high level description",
      "fields":[{"name":"...","type":"...","description":"..."}],
      "methods":[
        {
          "name":"...",
          "description":"...",
          "parameters":[{"name":"...","type":"...","description":"..."}],
          "return":{"type":"...","description":"..."}
        }
      ]
    }
  ]
}
Do not invent classes, fields or methods that are not in the skeleton.
"""

def build_skeleton(type_obj: Dict[str, Any]) -> Dict[str, Any]:
    return {
        "className": type_obj["name"],
        "kind": type_obj.get("kind", ""),
        "modifiers": type_obj.get("modifiers", ""),
        "fields": type_obj.get("fields", []),
        "methods": [
            {
                "name": m.get("name"),
                "returnType": m.get("returnType"),
                "modifiers": m.get("modifiers"),
                "parameters": m.get("parameters", []),
            }
            for m in type_obj.get("methods", [])
        ],
        "innerClasses": [build_skeleton(ic) for ic in type_obj.get("innerClasses", [])],
    }


def generate_documentation_for_type(type_obj: Dict[str, Any]) -> Dict[str, Any]:
    attempts = 0
    best = None
    best_score = -1.0

    while attempts <= DOC_AUTO_RETRY:
        attempts += 1

        method_docs = []
        for m in type_obj.get("methods", []):
            ms = summarise_method(type_obj["name"], m)
            method_docs.append(
                {
                    "name": ms.method_name,
                    "summary": ms.description,
                    "parameters": ms.signature.get("parameters", []),
                    "returnType": ms.signature.get("returnType"),
                }
            )

        payload = {"skeleton": build_skeleton(type_obj), "methods": method_docs}
        doc_json = chat_json(DOC_SYSTEM_PROMPT, payload, max_tokens=1400)

        validation = validate_doc_against_ast(type_obj, doc_json)
        score = (
            validation["skeleton_validation"]["total_completeness_percentage"]
            + validation["description_validation"]["accuracy_percentage"]
            + validation["description_validation"]["completeness_percentage"]
        ) / 300.0  # normalise 0–1

        if score > best_score:
            best_score = score
            best = {"doc": doc_json, "validation": validation}

        if score >= DOC_VALIDATION_THRESHOLD:
            break

    return best

==================
backend/converter.py (documentation-first Spring Boot generation)

from __future__ import annotations
from typing import Dict, Any, List, Tuple
import base64
from pathlib import Path
from .llm_client import chat_json

CONVERTER_SYSTEM_PROMPT = """
You convert Java class documentation into Spring Boot Java 11 code.

Input: the documentation JSON with "components" for one class.

Output JSON:
{
  "files":[{"path":"src/main/java/.../SomeClass.java","content":"<base64>"}],
  "notes":"short explanation",
  "pom":"<base64-encoded pom.xml or empty string>"
}

Rules:
- Use Java 11.
- Use Spring Boot 3.x style annotations.
- Do NOT use Lombok.
- Only use information contained in the documentation. If something is missing, keep code minimal and leave TODO comments.
"""

def convert_doc_to_spring(doc: Dict[str, Any]) -> Dict[str, Any]:
    j = chat_json(CONVERTER_SYSTEM_PROMPT, doc, max_tokens=2200)
    files: List[Tuple[str, str]] = []
    for f in j.get("files", []):
        path = f.get("path")
        try:
            content = base64.b64decode(f.get("content", "")).decode("utf-8")
        except Exception:
            content = f.get("content", "")
        files.append((path, content))

    pom_content = ""
    if "pom" in j:
        try:
            pom_content = base64.b64decode(j["pom"]).decode("utf-8")
        except Exception:
            pom_content = j["pom"]

    return {"files": files, "pom": pom_content, "notes": j.get("notes", "")}

===≈==============

backend/test_generator.py (JUnit from docs)

from __future__ import annotations
from typing import Dict, Any, List, Tuple
import base64
from .llm_client import chat_json

TEST_SYSTEM_PROMPT = """
You generate JUnit 5 tests for Spring Boot code based on the documentation JSON.

Output JSON:
{"tests":[{"path":"src/test/java/.../SomeClassTest.java","content":"<base64>"}]}
"""

def generate_tests(doc: Dict[str, Any]) -> List[Tuple[str, str]]:
    j = chat_json(TEST_SYSTEM_PROMPT, doc, max_tokens=1600)
    tests: List[Tuple[str, str]] = []
    for t in j.get("tests", []):
        path = t.get("path")
        try:
            content = base64.b64decode(t.get("content", "")).decode("utf-8")
        except Exception:
            content = t.get("content", "")
        tests.append((path, content))
    return tests

==================
4. Streamlit app (multi-class, UI similar to your screenshots)

from __future__ import annotations
import json
import os
from pathlib import Path
from typing import Dict, Any

import pandas as pd
import streamlit as st

from backend.config import (
    AST_JSON_PATH,
    PREPROCESSED_JSON,
    DATA_DIR,
    LEGACY_REPO_ENV,
)
from backend.ast_extractor import load_ast, run_java_extractor
from backend.chunker import flatten_types
from backend.doc_generator import generate_documentation_for_type
from backend.converter import convert_doc_to_spring
from backend.test_generator import generate_tests

# ---------- bootstrap ----------

st.set_page_config(page_title="Code Conversion Tool", layout="wide")
st.title("Code Conversion Tool")

repo_path = os.getenv(LEGACY_REPO_ENV)
if not repo_path:
    st.error(f"Set environment variable {LEGACY_REPO_ENV} to your legacy Java repo path.")
    st.stop()

if not AST_JSON_PATH.exists():
    with st.spinner("Running JavaParser extractor (one-time)..."):
        run_java_extractor(repo_path)

# cached AST for all pages
@st.cache_data
def get_ast() -> Dict[str, Any]:
    return load_ast()

ast = get_ast()

# preprocessed docs + metrics
def load_pre() -> Dict[str, Any]:
    if PREPROCESSED_JSON.exists():
        return json.loads(PREPROCESSED_JSON.read_text(encoding="utf-8"))
    return {"generation_details": {}}

def save_pre(data: Dict[str, Any]):
    PREPROCESSED_JSON.write_text(json.dumps(data, indent=2), encoding="utf-8")

pre = load_pre()

# flatten all types (top-level + inner)
all_types = flatten_types(ast)

# ---------- sidebar: class selection ----------

type_names = [t["qualified_name"] for t in all_types]
selected = st.sidebar.selectbox("Select Class", type_names)

st.sidebar.markdown("---")
if st.sidebar.button("Generate docs for ALL classes"):
    with st.spinner("Generating documentation for all classes... this may take a while."):
        for t in all_types:
            qname = t["qualified_name"]
            if qname in pre["generation_details"]:
                continue
            result = generate_documentation_for_type(t["type_obj"])
            pre["generation_details"][qname] = result
        save_pre(pre)
    st.sidebar.success("Docs generated for all classes.")


# ---------- main grid: table + detail ----------

left, right = st.columns([1.2, 1.8])

with left:
    st.subheader("Legacy Code Classes")

    rows = []
    for t in all_types:
        qname = t["qualified_name"]
        info = pre["generation_details"].get(qname)
        status = "Generated" if info else "Pending"
        completeness = ""
        if info:
            s = info["validation"]["skeleton_validation"]["total_completeness_percentage"]
            dacc = info["validation"]["description_validation"]["accuracy_percentage"]
            dcomp = info["validation"]["description_validation"]["completeness_percentage"]
            completeness = f"{(s + dacc + dcomp) / 3.0:.1f}%"
        rows.append(
            {
                "Qualified Class": qname,
                "File": t["file"],
                "Doc Status": status,
                "Doc Quality": completeness,
            }
        )

    df = pd.DataFrame(rows)
    st.dataframe(df, use_container_width=True)

with right:
    st.subheader(f"Documentation: {selected}")

    selected_type = next(t for t in all_types if t["qualified_name"] == selected)

    if selected not in pre["generation_details"]:
        if st.button("Generate documentation"):
            with st.spinner("Generating documentation via Azure OpenAI..."):
                result = generate_documentation_for_type(selected_type["type_obj"])
                pre["generation_details"][selected] = result
                save_pre(pre)
            st.experimental_rerun()
        else:
            st.info("Documentation not generated yet. Click the button above.")
    else:
        details = pre["generation_details"][selected]
        doc_json = details["doc"]
        validation = details["validation"]

        # top buttons
        b1, b2 = st.columns(2)
        with b1:
            if st.button("Re-generate documentation"):
                with st.spinner("Re-generating documentation..."):
                    result = generate_documentation_for_type(selected_type["type_obj"])
                    pre["generation_details"][selected] = result
                    save_pre(pre)
                st.experimental_rerun()
        with b2:
            if st.button("Convert to Spring & Generate Tests"):
                with st.spinner("Generating Spring Boot code..."):
                    conv = convert_doc_to_spring(doc_json)
                out_dir = DATA_DIR.parent / "generated"
                out_dir.mkdir(parents=True, exist_ok=True)

                # write pom once if provided
                if conv["pom"]:
                    (out_dir / "pom.xml").write_text(conv["pom"], encoding="utf-8")
                for path, content in conv["files"]:
                    p = out_dir / path
                    p.parent.mkdir(parents=True, exist_ok=True)
                    p.write_text(content, encoding="utf-8")

                with st.spinner("Generating tests..."):
                    tests = generate_tests(doc_json)
                for path, content in tests:
                    p = out_dir / path
                    p.parent.mkdir(parents=True, exist_ok=True)
                    p.write_text(content, encoding="utf-8")

                st.success(
                    f"Generated {len(conv['files'])} Spring files and {len(tests)} tests into {out_dir}."
                )
                if conv["notes"]:
                    st.write("Notes from generator:")
                    st.write(conv["notes"])

        st.markdown("### Documentation JSON")
        st.json(doc_json)

        st.markdown("### Validation Metrics")
        col1, col2 = st.columns(2)
        with col1:
            st.write("Skeleton Validation")
            st.json(validation["skeleton_validation"])
        with col2:
            st.write("Description Validation")
            st.json(validation["description_validation"])

==============
===============================================================
chunker.py

from __future__ import annotations
from dataclasses import dataclass
from typing import Any, Dict, List
from .llm_client import chat_json

SEGMENTER_SYSTEM_PROMPT = """
You are helping to refactor a huge legacy Java god class into logical modules.

You receive a JSON with:
{
  "className": "...",
  "methods": [
    {"name":"...", "parameters":"[String a, int b]", "returnType":"void"},
    ...
  ]
}

Group methods into coherent modules (services) based on their names and likely responsibilities.

Return JSON:

{
  "modules":[
    {
      "name":"UserService",
      "purpose":"short description",
      "methods":["login","registerUser","resetPassword"]
    },
    {
      "name":"ChequeProcessingService",
      "purpose":"...",
      "methods":["processCheque","cancelCheque","processChequeBatch"]
    }
  ]
}

Rules:
- Every method must belong to exactly one module.
- Prefer 4-10 methods per module; if very many, create more modules.
- Do NOT invent methods that don't exist in the input.
"""

@dataclass
class Segment:
    segment_id: str
    file_path: str
    origin_class: str
    module_name: str
    module_purpose: str
    methods: List[Dict[str, Any]]
    type_obj: Dict[str, Any]


def _segment_single_class(file_path: str, type_obj: Dict[str, Any]) -> List[Segment]:
    """
    For one AST class (like MainApplication), ask LLM to group methods into modules.
    """
    methods = type_obj.get("methods", [])
    if not methods:
        return []

    # If class is small, just one module = class itself
    if len(methods) <= 8:
        seg_id = f"{file_path}::{type_obj['name']}::Default"
        return [
            Segment(
                segment_id=seg_id,
                file_path=file_path,
                origin_class=type_obj["name"],
                module_name=type_obj["name"],
                module_purpose=f"Module representing class {type_obj['name']}",
                methods=methods,
                type_obj=type_obj,
            )
        ]

    payload = {
        "className": type_obj["name"],
        "methods": [
            {
                "name": m.get("name"),
                "parameters": m.get("parameters"),
                "returnType": m.get("returnType"),
            }
            for m in methods
        ],
    }

    result = chat_json(SEGMENTER_SYSTEM_PROMPT, payload, max_tokens=1200)
    modules = result.get("modules", [])

    # Map method name -> method object
    method_by_name = {m.get("name"): m for m in methods}
    segments: List[Segment] = []

    for idx, mod in enumerate(modules, start=1):
        m_names = mod.get("methods", [])
        seg_methods = [method_by_name[n] for n in m_names if n in method_by_name]
        if not seg_methods:
            continue
        module_name = mod.get("name") or f"{type_obj['name']}Module{idx}"
        seg_id = f"{file_path}::{type_obj['name']}::{module_name}"
        segments.append(
            Segment(
                segment_id=seg_id,
                file_path=file_path,
                origin_class=type_obj["name"],
                module_name=module_name,
                module_purpose=mod.get("purpose", ""),
                methods=seg_methods,
                type_obj=type_obj,
            )
        )

    # Fallback: if LLM messes up, create one module
    if not segments:
        seg_id = f"{file_path}::{type_obj['name']}::Default"
        return [
            Segment(
                segment_id=seg_id,
                file_path=file_path,
                origin_class=type_obj["name"],
                module_name=type_obj["name"],
                module_purpose=f"Module representing class {type_obj['name']}",
                methods=methods,
                type_obj=type_obj,
            )
        ]

    return segments


def build_segments(ast_json: Dict[str, Any]) -> List[Segment]:
    """
    From full AST JSON, build module segments for all classes.
    """
    all_segments: List[Segment] = []
    for f in ast_json.get("files", []):
        path = f.get("path", "")
        for t in f.get("types", []):
            all_segments.extend(_segment_single_class(path, t))
    return all_segments

=============================================================================================
doc_generator.py

from __future__ import annotations
import json
from typing import Dict, Any
from .chunker import Segment
from .llm_client import chat_json
from .validator import validate_doc_for_segment
from .config import DOC_AUTO_RETRY, DOC_VALIDATION_THRESHOLD

DOC_SYSTEM_PROMPT = """
You document ONE logical module extracted from a legacy Java application.

Input JSON:
{
  "module_name":"...",
  "origin_class":"...",
  "purpose":"short description of module",
  "methods":[
    {"name":"...","parameters":"[String a, int b]","returnType":"void"},
    ...
  ]
}

Return JSON:

{
  "module_name":"...",
  "description":"high-level description of responsibilities",
  "methods":[
    {
      "name":"...",
      "description":"what this method does",
      "parameters":[
        {"name":"...", "type":"...", "description":"..."}
      ],
      "return":{"type":"...", "description":"..."}
    }
  ]
}

Rules:
- Do NOT invent methods that are not present.
- Use method names and parameter types to infer behaviour.
"""

def generate_documentation_for_segment(seg: Segment) -> Dict[str, Any]:
    attempts = 0
    best = None
    best_score = -1.0

    payload = {
        "module_name": seg.module_name,
        "origin_class": seg.origin_class,
        "purpose": seg.module_purpose,
        "methods": seg.methods,
    }

    while attempts <= DOC_AUTO_RETRY:
        attempts += 1
        doc = chat_json(DOC_SYSTEM_PROMPT, payload, max_tokens=1600)
        validation = validate_doc_for_segment(seg, doc)
        score = (
            validation["method_coverage_percentage"]
            + validation["description_quality_estimate"]
        ) / 200.0  # normalise 0–1

        if score > best_score:
            best_score = score
            best = {"doc": doc, "validation": validation}

        if score >= DOC_VALIDATION_THRESHOLD:
            break

    return best

=============================================================
validator.py

from __future__ import annotations
from typing import Dict, Any, Set
from .chunker import Segment
from .llm_client import chat_json

DESCRIPTION_VALIDATOR_SYSTEM = """
You validate the quality of documentation for one module.

Input JSON:
{
  "module_name":"...",
  "origin_class":"...",
  "methods_in_code":["m1","m2",...],
  "methods_in_doc":["m1","m2",...],
  "doc_description":"..."
}

Return JSON:
{
  "description_quality_estimate": 90.0,
  "comments":"short explanation"
}
"""

def validate_doc_for_segment(seg: Segment, doc: Dict[str, Any]) -> Dict[str, Any]:
    code_methods: Set[str] = {m.get("name") for m in seg.methods}
    doc_methods: Set[str] = {m.get("name") for m in doc.get("methods", [])}

    total = len(code_methods) or 1
    coverage = len(code_methods & doc_methods) / total

    payload = {
        "module_name": seg.module_name,
        "origin_class": seg.origin_class,
        "methods_in_code": sorted(code_methods),
        "methods_in_doc": sorted(doc_methods),
        "doc_description": doc.get("description", ""),
    }
    j = chat_json(DESCRIPTION_VALIDATOR_SYSTEM, payload, max_tokens=600)

    return {
        "method_coverage_percentage": coverage * 100.0,
        "missing_methods": sorted(list(code_methods - doc_methods)),
        "description_quality_estimate": j.get("description_quality_estimate", 0.0),
        "comments": j.get("comments", ""),
    }

======================================================
convertor.py

from __future__ import annotations
from typing import Dict, Any, List, Tuple
import base64
from .llm_client import chat_json

CONVERTER_SYSTEM_PROMPT = """
You convert documentation of ONE module into Spring Boot Java 11 code.

Input JSON = the documentation object:
{
  "module_name":"ChequeProcessingService",
  "description":"...",
  "methods":[{...}]
}

Output JSON:
{
  "files":[
    {"path":"src/main/java/com/legacyconv/service/ChequeProcessingService.java","content":"<base64>"},
    {"path":"src/main/java/com/legacyconv/controller/ChequeProcessingController.java","content":"<base64 or plain text>"}
  ],
  "pom":"<optional base64 pom.xml, blank if not needed>",
  "notes":"short explanation of architecture choices"
}

Rules:
- Java 11, Spring Boot 3 style.
- Use @Service for business logic, @RestController for endpoints.
- Use DTOs for request/response where appropriate.
- Only implement methods described in the documentation.
- If details are missing, add TODO comments but keep code compiling.
"""

def convert_doc_to_spring(doc: Dict[str, Any]) -> Dict[str, Any]:
    j = chat_json(CONVERTER_SYSTEM_PROMPT, doc, max_tokens=2200)
    files: List[Tuple[str, str]] = []
    for f in j.get("files", []):
        path = f.get("path")
        raw = f.get("content", "")
        try:
            content = base64.b64decode(raw).decode("utf-8")
        except Exception:
            content = raw
        files.append((path, content))

    pom_content = ""
    raw_pom = j.get("pom", "")
    if raw_pom:
        try:
            pom_content = base64.b64decode(raw_pom).decode("utf-8")
        except Exception:
            pom_content = raw_pom

    return {"files": files, "pom": pom_content, "notes": j.get("notes", "")}
======================================================
test_generator.py

from __future__ import annotations
from typing import Dict, Any, List, Tuple
import base64
from .llm_client import chat_json

TEST_SYSTEM_PROMPT = """
You write JUnit 5 tests for Spring Boot services/controllers
based only on the module documentation JSON.

Input: the same documentation JSON.

Output JSON:
{
  "tests":[
    {"path":"src/test/java/com/legacyconv/service/ChequeProcessingServiceTest.java","content":"<base64 or code>"}
  ]
}
"""

def generate_tests(doc: Dict[str, Any]) -> List[Tuple[str, str]]:
    j = chat_json(TEST_SYSTEM_PROMPT, doc, max_tokens=1600)
    tests: List[Tuple[str, str]] = []
    for t in j.get("tests", []):
        path = t.get("path")
        raw = t.get("content", "")
        try:
            content = base64.b64decode(raw).decode("utf-8")
        except Exception:
            content = raw
        tests.append((path, content))
    return tests

==================================

app.py 


from __future__ import annotations
import json
import os
from pathlib import Path
from typing import Dict, Any

import pandas as pd
import streamlit as st

from backend.config import AST_JSON_PATH, PREPROCESSED_JSON, DATA_DIR, LEGACY_REPO_ENV
from backend.ast_extractor import load_ast, run_java_extractor
from backend.chunker import build_segments, Segment
from backend.doc_generator import generate_documentation_for_segment
from backend.converter import convert_doc_to_spring
from backend.test_generator import generate_tests

st.set_page_config(page_title="Legacy → SpringBoot Converter", layout="wide")
st.title("Legacy Code Conversion Tool (Multi-Module Segmentation)")

# --- environment check ---
repo_path = os.getenv(LEGACY_REPO_ENV)
if not repo_path:
    st.error(f"Set environment variable {LEGACY_REPO_ENV} to your legacy Java repo path.")
    st.stop()

repo_path = str(Path(repo_path).resolve())
st.sidebar.markdown(f"**Legacy repo:** `{repo_path}`")

if not AST_JSON_PATH.exists():
    with st.spinner("Running JavaParser extractor for the first time..."):
        run_java_extractor(repo_path)


@st.cache_data
def get_ast() -> Dict[str, Any]:
    return load_ast()


@st.cache_data
def get_segments() -> Dict[str, Segment]:
    ast = get_ast()
    seg_list = build_segments(ast)
    return {seg.segment_id: seg for seg in seg_list}


def load_pre() -> Dict[str, Any]:
    if PREPROCESSED_JSON.exists():
        return json.loads(PREPROCESSED_JSON.read_text(encoding="utf-8"))
    return {"generation_details": {}}


def save_pre(data: Dict[str, Any]):
    PREPROCESSED_JSON.write_text(json.dumps(data, indent=2), encoding="utf-8")


segments = get_segments()
pre = load_pre()

segment_ids = list(segments.keys())
if not segment_ids:
    st.error("No segments found in AST. Check that your legacy repo contains .java files.")
    st.stop()

# Sidebar selector
selected_id = st.sidebar.selectbox("Select Module Segment", segment_ids)

# Table of segments
left, right = st.columns([1.3, 1.7])

with left:
    rows = []
    for seg_id, seg in segments.items():
        info = pre["generation_details"].get(seg_id)
        status = "Generated" if info else "Pending"
        quality = ""
        if info:
            v = info["validation"]
            cov = v["method_coverage_percentage"]
            qual = v["description_quality_estimate"]
            quality = f"{(cov + qual) / 2.0:.1f}%"
        rows.append(
            {
                "Segment ID": seg_id,
                "Module": seg.module_name,
                "Origin Class": seg.origin_class,
                "File": seg.file_path,
                "Doc Status": status,
                "Doc Quality": quality,
            }
        )
    df = pd.DataFrame(rows)
    st.subheader("Segments (Modules)")
    st.dataframe(df, use_container_width=True)

with right:
    seg = segments[selected_id]
    st.subheader(f"Module: {seg.module_name}")
    st.caption(f"Origin class: {seg.origin_class}  •  File: {seg.file_path}")
    st.write(f"**LLM-inferred purpose:** {seg.module_purpose or '(not set)'}")

    if selected_id not in pre["generation_details"]:
        if st.button("Generate Documentation for this Module"):
            with st.spinner("Generating documentation via Azure OpenAI..."):
                result = generate_documentation_for_segment(seg)
                pre["generation_details"][selected_id] = result
                save_pre(pre)
            st.experimental_rerun()
        else:
            st.info("Documentation not generated yet. Click the button above.")
    else:
        details = pre["generation_details"][selected_id]
        doc = details["doc"]
        validation = details["validation"]

        b1, b2 = st.columns(2)
        with b1:
            if st.button("Re-Generate Documentation"):
                with st.spinner("Re-generating documentation..."):
                    result = generate_documentation_for_segment(seg)
                    pre["generation_details"][selected_id] = result
                    save_pre(pre)
                st.experimental_rerun()
        with b2:
            if st.button("Convert to Spring Boot & Generate Tests"):
                with st.spinner("Generating Spring Boot code..."):
                    conv = convert_doc_to_spring(doc)
                out_dir = DATA_DIR.parent / "generated"
                out_dir.mkdir(parents=True, exist_ok=True)

                if conv["pom"]:
                    (out_dir / "pom.xml").write_text(conv["pom"], encoding="utf-8")
                for path, content in conv["files"]:
                    p = out_dir / path
                    p.parent.mkdir(parents=True, exist_ok=True)
                    p.write_text(content, encoding="utf-8")

                with st.spinner("Generating tests..."):
                    tests = generate_tests(doc)
                for path, content in tests:
                    p = out_dir / path
                    p.parent.mkdir(parents=True, exist_ok=True)
                    p.write_text(content, encoding="utf-8")

                st.success(
                    f"Generated {len(conv['files'])} Spring Boot files and {len(tests)} tests under `{out_dir}`."
                )
                if conv["notes"]:
                    st.write("Notes from generator:")
                    st.write(conv["notes"])

        st.markdown("### Documentation JSON")
        st.json(doc)

        st.markdown("### Validation")
        c1, c2 = st.columns(2)
        with c1:
            st.write("Coverage & Quality")
            st.json(
                {
                    "method_coverage_percentage": validation["method_coverage_percentage"],
                    "description_quality_estimate": validation["description_quality_estimate"],
                }
            )
        with c2:
            st.write("Missing Methods / Comments")
            st.json(
                {
                    "missing_methods": validation["missing_methods"],
                    "comments": validation["comments"],
                }
            )
